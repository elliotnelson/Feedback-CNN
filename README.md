# Interpretability of Adversarial Attacks in Hidden Layers 

This is a repository for studying the influence of noise from adversarial examples on hidden layer activation patterns in VGG and ResNet. It is adapted from https://github.com/caochunshui/Feedback-CNN.

Slides to a short talk available here: https://www.slideshare.net/ElliotNelson3/understanding-adversarial-examples/1
